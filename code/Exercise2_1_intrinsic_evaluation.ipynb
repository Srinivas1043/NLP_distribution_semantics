{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Exercise2.1_intrinsic_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Z04wVGvAN5",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2.1 : Intrinsic Evaluation\n",
        "\n",
        "## Acknowledgement\n",
        "\n",
        "This notebook contains components of a notebook created by Pia Sommerauer. \n",
        "The original notebook (with more slides and examples, including code to create word embeddings) can be found here:\n",
        "\n",
        "https://github.com/PiaSommerauer/distributional_semantics\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook walks you through Exercise 2.1 of Assignment 2. The goal of this exercise is to (1) get hands on experience in comparing word embeddings, and (2) carry out an intrinsic evaluation and reflect on it.\n",
        "\n",
        "The notebook illustrates:\n",
        "\n",
        "* how to load a distributional semantic model in Python (with indications of where to obtain such models)\n",
        "* how to calculate distances between vectors\n",
        "* how to create a ranking between vector pairs based on distances and compare this to a gold ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-dGq4oGvAN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will be using gensim: https://pypi.org/project/gensim/\n",
        "# It provides implementations of various forms of language modeling\n",
        "# including functions to create and work with word embeddings\n",
        "\n",
        "# You can install gensim by running `pip install gensim' on your commandline \n",
        "# You can run this from the notebook by uncommenting the line below:\n",
        "# %pip install gensim\n",
        "\n",
        "# Other packages you may want to install if you do not have them installed already\n",
        "# %pip install pandas\n",
        "# %pip install scipy\n",
        "\n",
        "\n",
        "# You will only need to install each module once, so if you end up running this notebook multiple times,\n",
        "# you'll want to skip this cell or comment the packages you have installed out again.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0wFMeRJvAOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "# for loading a stored model \n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# pandas is a useful package for dealing with data structures\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fYI4g6tvAOK",
        "colab_type": "text"
      },
      "source": [
        "## Downloading a distributional semantic model\n",
        "\n",
        "There are many high quality distributional semantic models available. They are created from large corpora and have large coverage. Creating such models requires a lot of data and computation, and the more data, the better the model.\n",
        "You are therefore generally best of using one of these pretrained models.\n",
        "\n",
        "Sommerauer's notebook walks you through creating your own models (https://github.com/PiaSommerauer/distributional_semantics)\n",
        "\n",
        "For the exercises for this component, we will use existing models. \n",
        "\n",
        "***Note though: these models are big!***\n",
        "\n",
        "The Google word embeddings created using word2vec can be found here (which we are using in the examples):\n",
        "\n",
        "https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "Glove also has embeddings which take up a bit less space:\n",
        "\n",
        "https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Note though, that you may have to apply a small conversion procedure before the gensim code works with glove embeddings (they are formatted slightly differently from the output of word2vec).\n",
        "\n",
        "It is explained here: https://radimrehurek.com/gensim/scripts/glove2word2vec.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHKhitPzvAOK",
        "colab_type": "code",
        "outputId": "308a75cb-0e78-48ff-f0c5-86c3eb12542d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#loading a stored model. \n",
        "\n",
        "# Please make sure that the path `../models/GoogleNews-vectors-negative300.bin.gz' points to the location where you stored your word embeddings \n",
        "# if you are using a non-binary model, you will need to change binary=True to binary=False\n",
        "ds_model = KeyedVectors.load_word2vec_format('https://mynlpbucket2663523.s3-ap-southeast-1.amazonaws.com/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "# a first test with the model (you can replace \"student\" by other words)\n",
        "ds_model.most_similar(\"cricket\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4939422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWFOAF-pvAON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# similarity: a small scale experiment. Feel free to play with this and replace the terms\n",
        "\n",
        "cos_man_woman = ds_model.similarity('man', 'woman')\n",
        "cos_man_dog = ds_model.similarity('man', 'dog')\n",
        "\n",
        "cos_tree_plant = ds_model.similarity('tree','plant')\n",
        "cos_plant_flower = ds_model.similarity('plant','flower')\n",
        "\n",
        "print(f'Man and woman should be more similar than man and dog:')\n",
        "if cos_man_woman > cos_man_dog:\n",
        "    print('True!')\n",
        "    print('man-woman', cos_man_woman)\n",
        "    print('man-dog', cos_man_dog)\n",
        "else:\n",
        "    print('False')\n",
        "    print('man-woman', cos_man_woman)\n",
        "    print('man-dog', cos_man_dog)\n",
        "if cos_tree_plant > cos_plant_flower:\n",
        "    print('True!')\n",
        "    print('tree-plant', cos_tree_plant)\n",
        "    print('plant-flower', cos_plant_flower)\n",
        "else: \n",
        " \n",
        "    print('False!')\n",
        "    print('tree-plamt',cos_tree_plant)\n",
        "    print('plant-flower',cos_plant_flower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFaV5K68vAOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simlex_data = pd.read_csv('https://mynlpbucket2663523.s3-ap-southeast-1.amazonaws.com/SimLex-999.txt',sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waD6QNJpvAOV",
        "colab_type": "code",
        "outputId": "c90dafa6-8c60-4e59-c5fd-ab6f18bd4807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "ds_scores = {}\n",
        "human_scores = []\n",
        "model_scores = []\n",
        "\n",
        "for index, row in simlex_data.sort_values(by='SimLex999', ascending=False).iterrows():\n",
        "    wordpair = row['word1'] + '-' + row['word2']\n",
        "    human_scores.append(row['SimLex999'])\n",
        "    ds_score = ds_model.similarity(row['word1'],row['word2'])\n",
        "    model_scores.append(ds_score)\n",
        "    ds_scores[wordpair] = ds_model.similarity(row['word1'],row['word2'])\n",
        "\n",
        "    \n",
        "### Also saving the ranked output by the model to a file for inspection\n",
        "ds_ranked_output = open('ds_output_simlex_pairs.txt', 'w')\n",
        "for index, word_pair in enumerate(sorted(ds_scores, key=ds_scores.get, reverse=True)):\n",
        "    ds_ranked_output.write(str(index) + '\\t' + word_pair + '\\t' + str(ds_scores[word_pair]) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIA9n5HmvAOZ",
        "colab_type": "code",
        "outputId": "858cde1c-5b9f-42b7-c3b7-84f59b6d9aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#calculate spearman rho\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "spearmanr(human_scores, model_scores)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.44196551091403796, pvalue=5.068221892023142e-49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmKLmJhovAOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWE1V-eJvAOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}